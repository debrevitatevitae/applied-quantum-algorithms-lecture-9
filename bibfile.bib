@article{Schuld_2021_kernels,
  author        = {Maria Schuld},
  title         = {Supervised quantum machine learning models are kernel methods},
  year          = {2021},
  month         = jan,
  archiveprefix = {arXiv},
  eprint        = {2101.11020},
  file          = {:http\://arxiv.org/pdf/2101.11020v2:PDF;:Articles/2101.11020.pdf:PDF},
  keywords      = {quant-ph, stat.ML, qml},
  primaryclass  = {quant-ph}
}

@article{Liu_Arunachalam_Temme_21,
  author       = {Yunchao Liu and Srinivasan Arunachalam and Kristan Temme},
  title        = {A rigorous and robust quantum speed-up in supervised machine learning},
  date         = {2020-10-05},
  doi          = {10.1038/s41567-021-01287-z},
  eprint       = {2010.02174v2},
  eprintclass  = {quant-ph},
  eprinttype   = {arXiv},
  file         = {:Articles/s41567-021-01287-z.pdf:PDF;:Articles/2010.02174.pdf:PDF;online:http\://arxiv.org/pdf/2010.02174v2:PDF},
  journaltitle = {Nature Physics, 2021},
  keywords     = {quant-ph, cs.LG, qml}
}

@article{Lloyd2020a,
  author        = {Seth Lloyd and Maria Schuld and Aroosa Ijaz and Josh Izaac and Nathan Killoran},
  title         = {Quantum embeddings for machine learning},
  year          = {2020},
  month         = jan,
  abstract      = {Quantum classifiers are trainable quantum circuits used as machine learning models. The first part of the circuit implements a quantum feature map that encodes classical inputs into quantum states, embedding the data in a high-dimensional Hilbert space; the second part of the circuit executes a quantum measurement interpreted as the output of the model. Usually, the measurement is trained to distinguish quantum-embedded data. We propose to instead train the first part of the circuit -- the embedding -- with the objective of maximally separating data classes in Hilbert space, a strategy we call quantum metric learning. As a result, the measurement minimizing a linear classification loss is already known and depends on the metric used: for embeddings separating data using the l1 or trace distance, this is the Helstrom measurement, while for the l2 or Hilbert-Schmidt distance, it is a simple overlap measurement. This approach provides a powerful analytic framework for quantum machine learning and eliminates a major component in current models, freeing up more precious resources to best leverage the capabilities of near-term quantum information processors.},
  archiveprefix = {arXiv},
  eprint        = {2001.03622},
  file          = {:http\://arxiv.org/pdf/2001.03622v2:PDF;:Articles/2001.03622.pdf:PDF},
  keywords      = {quant-ph, qml},
  primaryclass  = {quant-ph},
  readstatus    = {read}
}

@article{Hubregtsen_2022,
  doi       = {10.1103/physreva.106.042431},
  url       = {https://doi.org/10.1103%2Fphysreva.106.042431},
  year      = 2022,
  month     = {oct},
  publisher = {American Physical Society ({APS})},
  volume    = {106},
  number    = {4},
  author    = {Thomas Hubregtsen and David Wierichs and Elies Gil-Fuster and Peter-Jan H. S. Derks and Paul K. Faehrmann and Johannes Jakob Meyer},
  title     = {Training quantum embedding kernels on near-term quantum computers},
  journal   = {Physical Review A}
}

@article{Wang2012,
  author    = {Tinghua Wang and Dongyan Zhao and Shengfeng Tian},
  journal   = {Artificial Intelligence Review},
  title     = {An overview of kernel alignment and its applications},
  year      = {2012},
  month     = {nov},
  number    = {2},
  pages     = {179--192},
  volume    = {43},
  doi       = {10.1007/s10462-012-9369-4},
  file      = {:Articles/s10462-012-9369-4.pdf:PDF},
  groups    = {machine learning - general},
  publisher = {Springer Science and Business Media {LLC}}
}
